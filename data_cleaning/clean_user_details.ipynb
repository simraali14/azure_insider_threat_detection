{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import to_timestamp, col, lit, input_file_name, udf\n",
        "import re\n",
        "\n",
        "# Function to extract date from filename\n",
        "def extract_date_from_filename(filename):\n",
        "    match = re.search(r'(\\d{4}-\\d{2})', filename)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "# Register the function as a UDF\n",
        "extract_date_udf = udf(extract_date_from_filename)\n",
        "\n",
        "# Load all CSV files in the LDAP folder\n",
        "folder_path = \"abfss://cyber-filesystem@cyberdatastore.dfs.core.windows.net/LDAP/*.csv\"\n",
        "\n",
        "# Read all CSV files in the folder\n",
        "df = spark.read.option(\"header\", \"true\").csv(folder_path)\n",
        "\n",
        "# Extract date from filename and add as a new column\n",
        "df = df.withColumn(\"date\", extract_date_udf(input_file_name()))\n",
        "df = df.withColumn(\"date\", to_timestamp(\"date\", \"MM/dd/yyyy HH:mm:ss\"))\n",
        "\n",
        "# Clean column names\n",
        "df_clean = df.select([col(c).alias(c.strip()) for c in df.columns if c.strip() != \"\"])\n",
        "df_clean = df_clean.withColumnRenamed(\"user_id\", \"user\")\n",
        "\n",
        "# Save the cleaned DataFrame as a table\n",
        "df_clean.write.mode(\"overwrite\").saveAsTable(\"clean_user_details\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "cybersparkpool",
              "statement_id": 3,
              "statement_ids": [
                3
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "37",
              "normalized_state": "finished",
              "queued_time": "2025-07-09T16:32:42.7553976Z",
              "session_start_time": null,
              "execution_start_time": "2025-07-09T16:32:42.7566756Z",
              "execution_finish_time": "2025-07-09T16:32:48.0543736Z",
              "parent_msg_id": "fa36f653-b3e3-4f11-a956-655091f73762"
            },
            "text/plain": "StatementMeta(cybersparkpool, 37, 3, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}