{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from synapse.ml.isolationforest import IsolationForest"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "cybersparkpool",
              "statement_id": 2,
              "statement_ids": [
                2
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "30",
              "normalized_state": "finished",
              "queued_time": "2025-07-08T22:32:34.8506814Z",
              "session_start_time": "2025-07-08T22:32:34.8516414Z",
              "execution_start_time": "2025-07-08T22:34:42.7521506Z",
              "execution_finish_time": "2025-07-08T22:34:48.0424213Z",
              "parent_msg_id": "ac98bb28-5cdd-4426-8541-b7823805b5dd"
            },
            "text/plain": "StatementMeta(cybersparkpool, 30, 2, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Load feature table\n",
        "feature_df = spark.read.table(\"model_features\").fillna(0)\n",
        "\n",
        "# Assemble features\n",
        "feature_columns = [col for col in feature_df.columns if col != 'user']\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "assembled_df = assembler.transform(feature_df).select(\"user\", \"features\")\n",
        "\n",
        "# Train Isolation Forest\n",
        "iforest = IsolationForest(\n",
        "    numEstimators=100, # number of trees\n",
        "    contamination=0.07, # assumes 7% of data is \"anomalous\"\n",
        "    featuresCol=\"features\",\n",
        "    predictionCol=\"prediction\" )\n",
        "\n",
        "model = iforest.fit(assembled_df)\n",
        "scored_df = model.transform(assembled_df)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "cybersparkpool",
              "statement_id": 3,
              "statement_ids": [
                3
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "30",
              "normalized_state": "finished",
              "queued_time": "2025-07-08T22:34:41.4120825Z",
              "session_start_time": null,
              "execution_start_time": "2025-07-08T22:34:48.0534016Z",
              "execution_finish_time": "2025-07-08T22:35:48.359496Z",
              "parent_msg_id": "554036dd-1226-422f-ad9b-2d77ef7535b6"
            },
            "text/plain": "StatementMeta(cybersparkpool, 30, 3, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results\n",
        "scored_df.write.mode(\"overwrite\").saveAsTable(\"user_anomaly_scores\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "cybersparkpool",
              "statement_id": 4,
              "statement_ids": [
                4
              ],
              "state": "finished",
              "livy_statement_state": "available",
              "spark_jobs": null,
              "session_id": "30",
              "normalized_state": "finished",
              "queued_time": "2025-07-08T22:35:59.7523541Z",
              "session_start_time": null,
              "execution_start_time": "2025-07-08T22:35:59.7535904Z",
              "execution_finish_time": "2025-07-08T22:36:06.531179Z",
              "parent_msg_id": "9df26f72-7bb8-4beb-8260-6149ba6259ac"
            },
            "text/plain": "StatementMeta(cybersparkpool, 30, 4, Finished, Available, Finished)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}