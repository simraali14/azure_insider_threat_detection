{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AOAI Insider Threat Analysis\n",
        "\n",
        "This notebook leverages Azure OpenAI (AOAI) to simulate the reasoning of a cybersecurity analyst. Once users have been nominated as anomalous from the (train_isolation_forest.ipynb script), this notebook can be used to further  and explain the users behavior. The goal is to analyze user behavior across multiple activity domains (device, email, file, HTTP, and logon) using both recent and baseline features.\n",
        "\n",
        "**AOAI prompt:**\n",
        "- Combines user background, engineered features, and raw event logs.\n",
        "- Encourages temporal and semantic reasoning to detect anomalies.\n",
        "- Produces a structured analysis summary including risk level, anomalous activities, and recommendations.\n",
        "\n",
        "**Example AOAI output:**\n",
        "- example_aoai_anomaly_analysis_output.md\n",
        "\n",
        "**Before running script:**\n",
        "- update \"api_key\" with your AOAI API Key\n",
        "- update \"user\" variable with the username of the user you would like to analyze\n",
        "- update \"max_logs\" variable with the max number of logs your deployment of AOAI can use (experiment with different values)\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "from openai import AzureOpenAI\n",
        "from IPython.display import Markdown, display"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to AOAI\n",
        "client = AzureOpenAI(\n",
        "    api_key=\"AOAI_API_KEY\", # REPLACE WITH YOUR KEY\n",
        "    api_version=\"2025-01-01-preview\",\n",
        "    azure_endpoint=\"https://cyber-aoai.openai.azure.com/\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Build prompt\n",
        "def build_prompt(user_id, user_details, features, device_logs, email_logs, file_logs, http_logs):\n",
        "    return f\"\"\"\n",
        "    You are a cybersecurity analyst assistant. Your task is to analyze user behavior logs and features to assess the risk of \n",
        "    insider threat activity. Use behavioral patterns, anomalies, and semantic cues to support your assessment. \n",
        "    Write in a concise, analytical tone.\n",
        "\n",
        "\n",
        "    ## User Profile\n",
        "    User ID: {user_id}\n",
        "    Background Information: {str(user_details)}\n",
        "\n",
        "    ## User Activity Features: {features}\n",
        "\n",
        "    Recent Device Events:\n",
        "    {device_logs}\n",
        "\n",
        "    Recent Email Events:\n",
        "    {email_logs}\n",
        "\n",
        "    Recent File Events:\n",
        "    {file_logs}\n",
        "\n",
        "    Recent HTTP Events:\n",
        "    {http_logs}\n",
        "\n",
        "    Analyze the logs and features below to assess potential insider threat behavior. Focus on:\n",
        "    - Patterns over time (e.g., spikes, shifts, or anomalies)\n",
        "    - Semantic meaning in the logs (e.g., risky URLs, external email activity)\n",
        "    - Deviations from baseline behavior\n",
        "\n",
        "    Use the structured template below to summarize your findings.\n",
        "\n",
        "    ## Analysis Output Template\n",
        "\n",
        "    **User Summary**\n",
        "    User: [Full Name] ({user_id}) — [1-sentence overview based on background]\n",
        "\n",
        "    **Behavior Summary**\n",
        "    [1-3 sentence summary of the user's recent behavior, highlighting any shifts or patterns]\n",
        "\n",
        "    **Anomalous Activities**\n",
        "    1. [Most notable suspicious activity with context]\n",
        "    2. [Second most notable activity]\n",
        "    3. [Optional third]\n",
        "\n",
        "    **Anomalous Timeline of Events**\n",
        "    - [Date Range 1] — [Summary of events or behavior]\n",
        "    - [Date Range 2] — [Summary of events or behavior]\n",
        "\n",
        "    **Risk Assessment**\n",
        "    - Risk Level: [Low / Medium / High]\n",
        "    - Justification: [Brief explanation based on data]\n",
        "\n",
        "    **Recommendations**\n",
        "    - [Suggested next steps: e.g., escalate, monitor, interview, etc.]\n",
        "\n",
        "    ---\n",
        "    Only use the data provided. Do not fabricate or assume information not present in the logs or features.\n",
        "    \"\"\""
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Anomalous User"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user = \"USERNAME\" # UPDATE WITH RELEVANT USERNAME\n",
        "max_logs = 500 # UPDATE DEPENDING ON AOAI PROMPT TOKEN LIMITS"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# pull recent user logs (number of events: max_logs)\n",
        "\n",
        "# device logs\n",
        "device_logs_df = spark.sql(f\"\"\"\n",
        "SELECT date, user, pc, activity\n",
        "FROM clean_device_events\n",
        "WHERE user = '{user}'\n",
        "ORDER BY date DESC\n",
        "LIMIT {max_logs}\n",
        "\"\"\").toPandas().drop(columns=['user'])\n",
        "\n",
        "# email logs\n",
        "email_logs_df = spark.sql(f\"\"\"\n",
        "SELECT date, user, pc, to, cc, bcc, from, size, attachments, content\n",
        "FROM clean_email_events\n",
        "WHERE user = '{user}'\n",
        "ORDER BY date DESC\n",
        "LIMIT {max_logs}\n",
        "\"\"\").toPandas().drop(columns=['user'])\n",
        "\n",
        "# file logs\n",
        "file_logs_df = spark.sql(f\"\"\"\n",
        "SELECT date, user, pc, filename, content\n",
        "FROM clean_file_events\n",
        "WHERE user = '{user}'\n",
        "ORDER BY date DESC\n",
        "LIMIT {max_logs}\n",
        "\"\"\").toPandas().drop(columns=['user'])\n",
        "\n",
        "# logon logs\n",
        "logon_logs_df = spark.sql(f\"\"\"\n",
        "SELECT date, user, pc, activity\n",
        "FROM clean_logon_events\n",
        "WHERE user = '{user}'\n",
        "ORDER BY date DESC\n",
        "LIMIT {max_logs}\n",
        "\"\"\").toPandas().drop(columns=['user'])\n",
        "\n",
        "# http logs\n",
        "http_logs_df = spark.sql(f\"\"\"\n",
        "SELECT date, user, pc, url\n",
        "FROM clean_http_events\n",
        "WHERE user = '{user}'\n",
        "ORDER BY date DESC\n",
        "LIMIT {max_logs}\n",
        "\"\"\").toPandas().drop(columns=['user'])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# format logs for AOAI prompt\n",
        "def format_logs(df, columns, max_rows=max_logs):\n",
        "    df = df.head(max_rows)\n",
        "    return \"\\n\".join([\" | \".join(str(row[col]) for col in columns) for _, row in df.iterrows()])\n",
        "\n",
        "device_logs_str = format_logs(device_logs_df, [\"date\", \"pc\", \"activity\"])\n",
        "email_logs_str = format_logs(email_logs_df, [\"date\", \"pc\", \"from\", \"to\", \"cc\", \"bcc\", \"size\", \"attachments\", \"content\"])\n",
        "file_logs_str = format_logs(file_logs_df, [\"date\", \"pc\", \"filename\", \"content\"])\n",
        "logon_logs_str = format_logs(logon_logs_df, [\"date\", \"pc\", \"activity\"])\n",
        "http_logs_str = format_logs(http_logs_df, [\"date\", \"pc\", \"url\"])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get users engineered features\n",
        "# (created from engineer_model_features.ipynb, stored in model_features table)\n",
        "\n",
        "features_df = spark.sql(f\"\"\"\n",
        "SELECT *\n",
        "FROM model_features\n",
        "WHERE user = '{user}'\n",
        "\"\"\").toPandas()\n",
        "\n",
        "# Convert the row to a dictionary\n",
        "if not features_df.empty:\n",
        "    features_dict = features_df.iloc[0].to_dict()\n",
        "else:\n",
        "    features_dict = {}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get users description\n",
        "# (LDAP details from clean_user_details.ipynb, stored in clean_user_details table)\n",
        "# includes employee background on users role, supervisor, etc\n",
        "\n",
        "user_details_df = spark.sql(f\"\"\"\n",
        "SELECT *\n",
        "FROM clean_user_details\n",
        "WHERE user = '{user}'\n",
        "\"\"\").toPandas()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit prompt to AOAI - with user engineered features, employee LDAP info, and event logs\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4.1\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a cybersecurity analyst assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": build_prompt(user, user_details_df, features_dict, device_logs_str, email_logs_str, file_logs_str, http_logs_str)}\n",
        "    ],\n",
        "    temperature=0.3,\n",
        "    max_tokens=1000\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Display analysis results\n",
        "aoai_output = response.choices[0].message.content\n",
        "display(Markdown(aoai_output))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}